{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü¶ã Bluesky Social Justice Data Collection & Analysis\n",
        "## DFP F25 Social Media Blue Team\n",
        "\n",
        "This notebook provides a comprehensive interface for collecting and analyzing social justice data from Bluesky using dual collection methods.\n",
        "\n",
        "## Collection Methods\n",
        "\n",
        "### **1. Firehose Collection (Real-time)**\n",
        "- Live stream of current posts as they happen\n",
        "- Best for monitoring ongoing conversations\n",
        "- Duration-based collection\n",
        "\n",
        "### **2. Search API Collection (Historical)**\n",
        "- Native search with deep pagination\n",
        "- Systematic historical data collection\n",
        "- Date range filtering and cursor-based navigation\n",
        "- Enhanced query design with exact phrases and hashtags\n",
        "\n",
        "### **3. Hybrid Collection (Both)**\n",
        "- Historical data first (search API)\n",
        "- Then real-time monitoring (firehose)\n",
        "- Complete coverage of past and present\n",
        "- Automatic time splitting: 75% search, 25% firehose\n",
        "\n",
        "### **Features:**\n",
        "- Dual collection methods (firehose + search API)\n",
        "- Deep pagination with cursor persistence\n",
        "- Date range filtering for historical collection\n",
        "- Author influence metrics (follower counts, verification)\n",
        "- Enhanced search queries (exact phrases, hashtags)\n",
        "- Session-based organization with alltime datasets\n",
        "- Rich content analysis (hashtags, media, emotions)\n",
        "- Secure authentication from external credentials file\n",
        "\n",
        "### **Why Author Metrics Matter:**\n",
        "- Firehose captures posts within seconds (engagement typically zero)\n",
        "- Follower counts provide immediate influence assessment\n",
        "- Essential for identifying high-impact voices in social justice content\n",
        "- Helps prioritize content before viral spread occurs\n",
        "\n",
        "### **Social Justice Keywords:**\n",
        "- Food insecurity\n",
        "- Housing crisis  \n",
        "- Homelessness\n",
        "- Unemployment\n",
        "- Gender inequality\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Setup and Dependencies\n",
        "\n",
        "First, let's import all required libraries and check our setup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ atproto library available\n",
            "üîß Setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timezone\n",
        "from collections import defaultdict, Counter\n",
        "import re\n",
        "\n",
        "# Check if atproto is available\n",
        "try:\n",
        "    from atproto import Client\n",
        "    print(\"‚úÖ atproto library available\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå atproto not found. Install with: pip install atproto\")\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üîß Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Load and Explore Collected Data\n",
        "\n",
        "Let's examine the social justice data we've collected from Bluesky.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Loading Alltime Data:\n",
            "========================================\n",
            "‚úÖ Food Insecurity: 2,152 posts\n",
            "‚úÖ Housing: 1,574 posts\n",
            "‚úÖ Homeless: 4,399 posts\n",
            "‚úÖ Unemployment: 4,329 posts\n",
            "‚úÖ Gender Inequality: 241 posts\n",
            "\n",
            "üìà Total Posts Loaded: 12,695\n",
            "‚úÖ DataFrame created with 12695 rows and 45 columns\n",
            "\n",
            "üîç Data Structure:\n",
            "   Post fields: uri, text, created_at, author_handle\n",
            "   Author fields: followers_count, influence_score, verified\n",
            "   Content fields: word_count, hashtags, emotion_score\n",
            "   Session fields: session_name, collected_at\n"
          ]
        }
      ],
      "source": [
        "# Load all alltime data for analysis\n",
        "keywords = [\"food_insecurity\", \"housing\", \"homeless\", \"unemployment\", \"gender_inequality\"]\n",
        "all_data = []\n",
        "keyword_counts = {}\n",
        "\n",
        "print(\"üìä Loading Alltime Data:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file):\n",
        "        keyword_posts = []\n",
        "        with open(alltime_file, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    post = json.loads(line.strip())\n",
        "                    all_data.append(post)\n",
        "                    keyword_posts.append(post)\n",
        "                except json.JSONDecodeError:\n",
        "                    continue\n",
        "        \n",
        "        keyword_counts[keyword] = len(keyword_posts)\n",
        "        print(f\"‚úÖ {keyword.replace('_', ' ').title()}: {len(keyword_posts):,} posts\")\n",
        "    else:\n",
        "        keyword_counts[keyword] = 0\n",
        "        print(f\"‚ùå {keyword.replace('_', ' ').title()}: No data\")\n",
        "\n",
        "print(f\"\\nüìà Total Posts Loaded: {len(all_data):,}\")\n",
        "\n",
        "# Convert to DataFrame for analysis\n",
        "if all_data:\n",
        "    df = pd.DataFrame(all_data)\n",
        "    print(f\"‚úÖ DataFrame created with {len(df)} rows and {len(df.columns)} columns\")\n",
        "    \n",
        "    # Show data structure\n",
        "    print(f\"\\nüîç Data Structure:\")\n",
        "    print(f\"   Post fields: uri, text, created_at, author_handle\")\n",
        "    print(f\"   Author fields: followers_count, influence_score, verified\")\n",
        "    print(f\"   Content fields: word_count, hashtags, emotion_score\")\n",
        "    print(f\"   Session fields: session_name, collected_at\")\n",
        "else:\n",
        "    df = pd.DataFrame()\n",
        "    print(\"‚ùå No data available - run collection first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìã Collection Method Details\n",
        "\n",
        "**üî• Firehose Collection** (Original Method)\n",
        "- **How it works**: Connects to live Bluesky firehose stream\n",
        "- **Data type**: Real-time posts as they happen\n",
        "- **Best for**: Monitoring current conversations, trending topics\n",
        "- **Parameters**: Duration in seconds/minutes\n",
        "- **Coverage**: Only new posts during collection window\n",
        "\n",
        "**üîç Search API Collection** (NEW - Option A Implementation)  \n",
        "- **How it works**: Uses `GET /xrpc/app.bsky.feed.searchPosts` with cursor pagination\n",
        "- **Data type**: Historical posts with deep pagination\n",
        "- **Best for**: Systematic research, historical analysis, comprehensive datasets\n",
        "- **Parameters**: Date ranges, maximum posts per keyword\n",
        "- **Coverage**: Can collect posts from weeks/months back\n",
        "- **Features**: \n",
        "  - Enhanced search queries (exact phrases, hashtags)\n",
        "  - Date range filtering (`record.createdAt` checking)\n",
        "  - Cursor-based pagination (no missed posts)\n",
        "  - Rate limiting and error handling\n",
        "\n",
        "**‚ö° Hybrid Collection** (RECOMMENDED)\n",
        "- **How it works**: Search API first for historical data, then firehose for real-time\n",
        "- **Data type**: Complete coverage of both historical and current data\n",
        "- **Best for**: Comprehensive research projects\n",
        "- **Parameters**: Both date ranges and duration\n",
        "- **Coverage**: Historical baseline + ongoing monitoring\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üîç Enhanced Search Queries (Option A)\n",
        "\n",
        "The new search API uses optimized queries designed to reduce noise and maximize relevant results:\n",
        "\n",
        "**Food Insecurity:**\n",
        "- `\"food insecurity\"`, `\"food insecure\"`, `#foodinsecurity`\n",
        "- `\"hunger crisis\"`, `\"food desert\"`, `\"SNAP benefits\"`\n",
        "- `\"food bank\"`, `\"food pantry\"`, `\"EBT\"`, `\"WIC\"`\n",
        "\n",
        "**Housing:**\n",
        "- `\"housing crisis\"`, `\"affordable housing\"`, `#housingcrisis`\n",
        "- `\"rent crisis\"`, `\"housing shortage\"`, `\"eviction\"`\n",
        "- `\"housing costs\"`, `\"rent burden\"`, `\"gentrification\"`\n",
        "\n",
        "**Homelessness:**\n",
        "- `\"homeless\"`, `\"homelessness\"`, `#homeless`\n",
        "- `\"unhoused\"`, `\"rough sleeping\"`, `\"encampment\"`\n",
        "- `\"shelter\"`, `\"street sleeping\"`, `\"housing first\"`\n",
        "\n",
        "**Unemployment:**\n",
        "- `\"unemployment\"`, `\"unemployed\"`, `#unemployment`\n",
        "- `\"job loss\"`, `\"layoffs\"`, `\"jobless\"`\n",
        "- `\"unemployment benefits\"`, `\"fired\"`, `\"laid off\"`\n",
        "\n",
        "**Gender Inequality:**\n",
        "- `\"gender inequality\"`, `\"gender gap\"`, `#gendergap`\n",
        "- `\"pay gap\"`, `\"wage gap\"`, `\"gender discrimination\"`\n",
        "- `\"equal pay\"`, `\"workplace inequality\"`, `\"glass ceiling\"`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Data Collection Execution\n",
        "\n",
        "### Collection Method Selection\n",
        "\n",
        "Choose your collection approach and set parameters below. The collector supports three methods:\n",
        "\n",
        "1. **Firehose**: Real-time stream collection\n",
        "2. **Search API**: Historical data with pagination  \n",
        "3. **Both**: Historical first, then real-time (hybrid approach)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Collection Configuration:\n",
            "   Method: both\n",
            "   Session: notebook_collection\n",
            "   Total Time: 1800 seconds (30.0 minutes)\n",
            "   Search Phase: 1350s (75%)\n",
            "   Firehose Phase: 450s (25%)\n",
            "   Search Days Back: 14 days\n",
            "   Max Posts/Keyword: 100\n",
            "   üìÅ Output: data/sessions/notebook_collection/ + data/alltime/\n"
          ]
        }
      ],
      "source": [
        "# üîß COLLECTION PARAMETERS - Edit these values\n",
        "\n",
        "# ===== COLLECTION METHOD =====\n",
        "# Choose: 'firehose', 'search', or 'both'\n",
        "COLLECTION_METHOD = \"both\"  # Options: firehose | search | both\n",
        "\n",
        "# ===== TIME MANAGEMENT =====\n",
        "# Option 1: Single time parameter (recommended for 'both' method)\n",
        "TOTAL_TIME_SECONDS = 1800  # Auto-splits: 75% search (225s), 25% firehose (75s)\n",
        "\n",
        "# Option 2: Separate time controls (alternative)\n",
        "# DURATION_SECONDS = 75      # Firehose duration\n",
        "# SEARCH_TIMEOUT = 225       # Search timeout\n",
        "\n",
        "# ===== SEARCH API PARAMETERS (for historical collection) =====\n",
        "DAYS_BACK = 14  # Days back from now (alternative to specific dates)\n",
        "# START_DATE = \"2024-09-01\"  # Optional: specific start date (YYYY-MM-DD)\n",
        "# END_DATE = \"2024-09-18\"    # Optional: specific end date (YYYY-MM-DD)\n",
        "MAX_POSTS_PER_KEYWORD = 100  # Maximum posts per keyword for search\n",
        "\n",
        "# ===== GENERAL PARAMETERS =====\n",
        "SESSION_NAME = \"notebook_collection\"  # Custom session name (optional)\n",
        "\n",
        "# Display configuration\n",
        "print(f\"üìä Collection Configuration:\")\n",
        "print(f\"   Method: {COLLECTION_METHOD}\")\n",
        "print(f\"   Session: {SESSION_NAME}\")\n",
        "\n",
        "if COLLECTION_METHOD == 'both' and 'TOTAL_TIME_SECONDS' in locals():\n",
        "    total_minutes = TOTAL_TIME_SECONDS / 60\n",
        "    search_time = int(TOTAL_TIME_SECONDS * 0.75)\n",
        "    firehose_time = int(TOTAL_TIME_SECONDS * 0.25)\n",
        "    print(f\"   Total Time: {TOTAL_TIME_SECONDS} seconds ({total_minutes:.1f} minutes)\")\n",
        "    print(f\"   Search Phase: {search_time}s (75%)\")\n",
        "    print(f\"   Firehose Phase: {firehose_time}s (25%)\")\n",
        "elif COLLECTION_METHOD in ['firehose', 'both'] and 'DURATION_SECONDS' in locals():\n",
        "    duration_minutes = DURATION_SECONDS / 60\n",
        "    print(f\"   Firehose Duration: {DURATION_SECONDS} seconds ({duration_minutes:.1f} minutes)\")\n",
        "\n",
        "if COLLECTION_METHOD in ['search', 'both']:\n",
        "    print(f\"   Search Days Back: {DAYS_BACK} days\")\n",
        "    print(f\"   Max Posts/Keyword: {MAX_POSTS_PER_KEYWORD}\")\n",
        "\n",
        "print(f\"   üìÅ Output: data/sessions/{SESSION_NAME}/ + data/alltime/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚ñ∂Ô∏è Execute HYBRID Collection\n",
        "\n",
        "Run the cell below to start data collection with your chosen method and parameters.\n",
        "\n",
        "**What happens:**\n",
        "- **üîç Search method**: Collects historical data using native search API with pagination\n",
        "- **üî• Firehose method**: Collects real-time data from live stream  \n",
        "- **‚ö° Both method**: Historical data first, then real-time (recommended for comprehensive coverage)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Current Alltime Data BEFORE Collection:\n",
            "==================================================\n",
            "   Food Insecurity: 2152 posts\n",
            "   Housing: 1574 posts\n",
            "   Homeless: 4399 posts\n",
            "   Unemployment: 4329 posts\n",
            "   Gender Inequality: 241 posts\n",
            "\n",
            "üìà Total Before: 12695 posts\n",
            "\n",
            "üöÄ Starting HYBRID Collection...\n",
            "   Method: both\n",
            "   Session: notebook_collection\n",
            "   üî• Firehose Duration: 300 seconds (5.0 minutes)\n",
            "   üîç Search Days Back: 14 days\n",
            "   üîç Max Posts/Keyword: 100\n",
            "   üîß Command: python bluesky_social_justice_collector.py --method both --session_name notebook_collection --total-time 1800 --days-back 14 --max-posts 100\n",
            "‚úÖ Collection completed!\n",
            "\n",
            "üìã Collection Output:\n",
            "------------------------------\n",
            "mployment\"': 36 posts\n",
            "   ‚è∞ Search timeout reached, stopping at query '\"unemployed\"'\n",
            "   üìä Total for 'unemployment': 36 posts\n",
            "\n",
            "‚è∞ Search timeout reached (1350s), stopping collection\n",
            "\n",
            "üíæ Final save: 36 posts\n",
            "\n",
            "üìà Search collection complete: 1524 total posts\n",
            "üîó Updating alltime files with search results...\n",
            "   üìä Alltime files updated:\n",
            "     food insecurity: +266 new (total: 2418)\n",
            "     housing: +536 new (total: 2110)\n",
            "     homeless: +686 new (total: 5085)\n",
            "     unemployment: +36 new (total: 4365)\n",
            "\n",
            "‚ö° Phase 2: Real-time data collection (Firehose)\n",
            "üîå Connecting to Bluesky firehose...\n",
            "‚úÖ Connected! Starting social justice data collection...\n",
            "   Session: notebook_collection\n",
            "   Duration: 7.5 minutes\n",
            "   Enhanced features: follower counts, profiles, content analysis\n",
            "\n",
            "‚è∞ Collection time completed (450 seconds)\n",
            "\n",
            "üßπ Finalizing collection...\n",
            "üîó Updating alltime files with complete session data...\n",
            "   üìä No new posts to add to alltime files\n",
            "\n",
            "üìä COLLECTION COMPLETE: notebook_collection\n",
            "============================================================\n",
            "Duration: 22.6 minutes\n",
            "Posts processed: 0\n",
            "Relevant posts: 0\n",
            "Profiles fetched: 5558\n",
            "Processing rate: 0.0 posts/second\n",
            "\n",
            "üë• Author Influence:\n",
            "   Average followers: 4409\n",
            "   Max followers: 931,108\n",
            "   Authors analyzed: 5534\n",
            "\n",
            "üîç Keywords collected:\n",
            "   food insecurity: 300 posts\n",
            "   housing: 567 posts\n",
            "   homeless: 686 posts\n",
            "   unemployment: 72 posts\n",
            "\n",
            "üìÅ Data saved to:\n",
            "   Session: data/sessions/notebook_collection/\n",
            "   Alltime: data/alltime/\n",
            "‚úÖ Social justice data collection completed\n",
            "\n",
            "\n",
            "‚è±Ô∏è Actual runtime: 22.7 minutes\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Check current alltime data BEFORE collection\n",
        "print(\"üìä Current Alltime Data BEFORE Collection:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "keywords = [\"food_insecurity\", \"housing\", \"homeless\", \"unemployment\", \"gender_inequality\"]\n",
        "before_counts = {}\n",
        "\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file):\n",
        "        with open(alltime_file, 'r') as f:\n",
        "            count = sum(1 for line in f)\n",
        "        before_counts[keyword] = count\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: {count} posts\")\n",
        "    else:\n",
        "        before_counts[keyword] = 0\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: 0 posts\")\n",
        "\n",
        "total_before = sum(before_counts.values())\n",
        "print(f\"\\nüìà Total Before: {total_before} posts\")\n",
        "\n",
        "print(f\"\\nüöÄ Starting HYBRID Collection...\")\n",
        "print(f\"   Method: {COLLECTION_METHOD}\")\n",
        "print(f\"   Session: {SESSION_NAME}\")\n",
        "\n",
        "if COLLECTION_METHOD in ['firehose', 'both']:\n",
        "    print(f\"   üî• Firehose Duration: {DURATION_SECONDS} seconds ({DURATION_SECONDS/60:.1f} minutes)\")\n",
        "if COLLECTION_METHOD in ['search', 'both']:\n",
        "    print(f\"   üîç Search Days Back: {DAYS_BACK} days\")\n",
        "    print(f\"   üîç Max Posts/Keyword: {MAX_POSTS_PER_KEYWORD}\")\n",
        "\n",
        "# Build command arguments\n",
        "cmd_args = [\n",
        "    'python', 'bluesky_social_justice_collector.py',\n",
        "    '--method', COLLECTION_METHOD,\n",
        "    '--session_name', SESSION_NAME\n",
        "]\n",
        "\n",
        "# Add time management arguments\n",
        "if COLLECTION_METHOD == 'both' and 'TOTAL_TIME_SECONDS' in locals():\n",
        "    # Use total-time parameter for automatic split\n",
        "    cmd_args.extend(['--total-time', str(TOTAL_TIME_SECONDS)])\n",
        "elif COLLECTION_METHOD in ['firehose', 'both'] and 'DURATION_SECONDS' in locals():\n",
        "    # Use separate duration parameter\n",
        "    cmd_args.extend(['--duration', str(DURATION_SECONDS)])\n",
        "\n",
        "# Add search timeout if specified\n",
        "if 'SEARCH_TIMEOUT' in locals():\n",
        "    cmd_args.extend(['--search-timeout', str(SEARCH_TIMEOUT)])\n",
        "\n",
        "# Add search parameters\n",
        "if COLLECTION_METHOD in ['search', 'both']:\n",
        "    if DAYS_BACK:\n",
        "        cmd_args.extend(['--days-back', str(DAYS_BACK)])\n",
        "    cmd_args.extend(['--max-posts', str(MAX_POSTS_PER_KEYWORD)])\n",
        "\n",
        "print(f\"   üîß Command: {' '.join(cmd_args)}\")\n",
        "\n",
        "# Run collection\n",
        "start_time = time.time()\n",
        "try:\n",
        "    # Set timeout based on method\n",
        "    timeout_seconds = 120  # Default for search\n",
        "    if COLLECTION_METHOD == 'both' and 'TOTAL_TIME_SECONDS' in locals():\n",
        "        timeout_seconds = TOTAL_TIME_SECONDS + 120\n",
        "    elif COLLECTION_METHOD in ['firehose', 'both'] and 'DURATION_SECONDS' in locals():\n",
        "        timeout_seconds = DURATION_SECONDS + 120\n",
        "    \n",
        "    result = subprocess.run(cmd_args, capture_output=True, text=True, timeout=timeout_seconds)\n",
        "    \n",
        "    print(\"‚úÖ Collection completed!\")\n",
        "    print(\"\\nüìã Collection Output:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(result.stdout[-1500:])  # Show last 1500 characters\n",
        "    \n",
        "    if result.stderr:\n",
        "        print(\"\\n‚ö†Ô∏è Warnings/Errors:\")\n",
        "        print(result.stderr[-500:])\n",
        "    \n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"‚è∞ Collection timed out (normal for long runs)\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Collection error: {e}\")\n",
        "\n",
        "actual_duration = time.time() - start_time\n",
        "print(f\"\\n‚è±Ô∏è Actual runtime: {actual_duration/60:.1f} minutes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Collection Results & Output Directory\n",
        "\n",
        "Check the results and see what data was collected.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Collection Results:\n",
            "==================================================\n",
            "   Food Insecurity: 2418 posts (+266 new)\n",
            "   Housing: 2110 posts (+536 new)\n",
            "   Homeless: 5085 posts (+686 new)\n",
            "   Unemployment: 4365 posts (+36 new)\n",
            "   Gender Inequality: 241 posts (+0 new)\n",
            "\n",
            "üìà Total Growth: 12695 ‚Üí 14219 (+1524 new posts)\n",
            "\n",
            "üìÅ Output Directories:\n",
            "   Session data: data/sessions/notebook_collection/\n",
            "   Alltime data: data/alltime/\n",
            "\n",
            "üìÇ Session Files Created:\n",
            "   homeless_posts.jsonl: 686 posts\n",
            "   food_insecurity_posts.jsonl: 266 posts\n",
            "   housing_posts.jsonl: 536 posts\n",
            "   unemployment_posts.jsonl: 36 posts\n",
            "\n",
            "üìù Sample of Latest Data:\n",
            "------------------------------\n",
            "\n",
            "üéØ Latest Food Insecurity post:\n",
            "   Author: @edgarallandoh.bsky.social\n",
            "   Followers: 2,614\n",
            "   Text: 5calls.org, help in local food bank, tutor children, exchange info on what skills/resources you have...\n",
            "   Session: notebook_collection\n"
          ]
        }
      ],
      "source": [
        "# Check AFTER collection results\n",
        "print(\"üìä Collection Results:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check alltime data AFTER collection\n",
        "after_counts = {}\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file):\n",
        "        with open(alltime_file, 'r') as f:\n",
        "            count = sum(1 for line in f)\n",
        "        after_counts[keyword] = count\n",
        "        growth = count - before_counts.get(keyword, 0)\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: {count} posts (+{growth} new)\")\n",
        "    else:\n",
        "        after_counts[keyword] = 0\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: 0 posts\")\n",
        "\n",
        "total_after = sum(after_counts.values())\n",
        "total_growth = total_after - total_before\n",
        "\n",
        "print(f\"\\nüìà Total Growth: {total_before} ‚Üí {total_after} (+{total_growth} new posts)\")\n",
        "\n",
        "# Show output directories\n",
        "print(f\"\\nüìÅ Output Directories:\")\n",
        "print(f\"   Session data: data/sessions/{SESSION_NAME}/\")\n",
        "print(f\"   Alltime data: data/alltime/\")\n",
        "\n",
        "# Check session directory\n",
        "session_dir = f\"data/sessions/{SESSION_NAME}\"\n",
        "if os.path.exists(session_dir):\n",
        "    session_files = [f for f in os.listdir(session_dir) if f.endswith('.jsonl')]\n",
        "    print(f\"\\nüìÇ Session Files Created:\")\n",
        "    for file in session_files:\n",
        "        file_path = os.path.join(session_dir, file)\n",
        "        with open(file_path, 'r') as f:\n",
        "            count = sum(1 for line in f)\n",
        "        print(f\"   {file}: {count} posts\")\n",
        "\n",
        "# Show sample of latest collected data\n",
        "print(f\"\\nüìù Sample of Latest Data:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file) and after_counts[keyword] > before_counts.get(keyword, 0):\n",
        "        try:\n",
        "            # Get last post\n",
        "            with open(alltime_file, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            if lines:\n",
        "                last_post = json.loads(lines[-1].strip())\n",
        "                print(f\"\\nüéØ Latest {keyword.replace('_', ' ').title()} post:\")\n",
        "                print(f\"   Author: @{last_post.get('author_handle', 'unknown')}\")\n",
        "                print(f\"   Followers: {last_post.get('author_followers_count', 0):,}\")\n",
        "                print(f\"   Text: {last_post.get('text', '')[:100]}...\")\n",
        "                print(f\"   Session: {last_post.get('session_name', 'unknown')}\")\n",
        "                break\n",
        "        except:\n",
        "            continue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
