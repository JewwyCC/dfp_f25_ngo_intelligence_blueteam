{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ¦‹ Bluesky Social Justice Data Collection & Analysis\n",
        "## DFP F25 Social Media Blue Team\n",
        "\n",
        "This notebook provides an interactive interface for collecting and analyzing social justice data from Bluesky with rich author influence metrics.\n",
        "\n",
        "**Key Features:**\n",
        "- âœ… **Real-time data collection** with Bluesky firehose\n",
        "- âœ… **Author influence metrics** (follower counts, verification status)\n",
        "- âœ… **Session-based organization** with alltime datasets\n",
        "- âœ… **2-minute batching** with automatic alltime updates\n",
        "- âœ… **Rich content analysis** (hashtags, media, emotions)\n",
        "- âœ… **Secure authentication** from external credentials file\n",
        "\n",
        "**Social Justice Keywords:**\n",
        "- Food insecurity\n",
        "- Housing crisis\n",
        "- Homelessness\n",
        "- Unemployment\n",
        "- Gender inequality\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ Setup and Dependencies\n",
        "\n",
        "First, let's import all required libraries and check our setup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timezone\n",
        "from collections import defaultdict, Counter\n",
        "import re\n",
        "\n",
        "# Check if atproto is available\n",
        "try:\n",
        "    from atproto import Client\n",
        "    print(\"âœ… atproto library available\")\n",
        "except ImportError:\n",
        "    print(\"âŒ atproto not found. Install with: pip install atproto\")\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"ðŸ”§ Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Load and Explore Collected Data\n",
        "\n",
        "Let's examine the social justice data we've collected from Bluesky.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load all alltime data for analysis\n",
        "keywords = [\"food_insecurity\", \"housing\", \"homeless\", \"unemployment\", \"gender_inequality\"]\n",
        "all_data = []\n",
        "keyword_counts = {}\n",
        "\n",
        "print(\"ðŸ“Š Loading Alltime Data:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file):\n",
        "        keyword_posts = []\n",
        "        with open(alltime_file, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    post = json.loads(line.strip())\n",
        "                    all_data.append(post)\n",
        "                    keyword_posts.append(post)\n",
        "                except json.JSONDecodeError:\n",
        "                    continue\n",
        "        \n",
        "        keyword_counts[keyword] = len(keyword_posts)\n",
        "        print(f\"âœ… {keyword.replace('_', ' ').title()}: {len(keyword_posts):,} posts\")\n",
        "    else:\n",
        "        keyword_counts[keyword] = 0\n",
        "        print(f\"âŒ {keyword.replace('_', ' ').title()}: No data\")\n",
        "\n",
        "print(f\"\\nðŸ“ˆ Total Posts Loaded: {len(all_data):,}\")\n",
        "\n",
        "# Convert to DataFrame for analysis\n",
        "if all_data:\n",
        "    df = pd.DataFrame(all_data)\n",
        "    print(f\"âœ… DataFrame created with {len(df)} rows and {len(df.columns)} columns\")\n",
        "    \n",
        "    # Show data structure\n",
        "    print(f\"\\nðŸ” Data Structure:\")\n",
        "    print(f\"   Post fields: uri, text, created_at, author_handle\")\n",
        "    print(f\"   Author fields: followers_count, influence_score, verified\")\n",
        "    print(f\"   Content fields: word_count, hashtags, emotion_score\")\n",
        "    print(f\"   Session fields: session_name, collected_at\")\n",
        "else:\n",
        "    df = pd.DataFrame()\n",
        "    print(\"âŒ No data available - run collection first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Data Collection Execution\n",
        "\n",
        "### Collection Parameters\n",
        "\n",
        "Set your collection duration below, then run the execution cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ”§ COLLECTION PARAMETERS - Edit these values\n",
        "DURATION_SECONDS = 300  # 5 minutes (change to 30, 600, 1200, 1800, 3600 as needed)\n",
        "SESSION_NAME = \"notebook_test\"  # Custom session name (optional)\n",
        "\n",
        "# Duration conversion helper\n",
        "duration_minutes = DURATION_SECONDS / 60\n",
        "print(f\"ðŸ“Š Collection Parameters:\")\n",
        "print(f\"   Duration: {DURATION_SECONDS} seconds ({duration_minutes:.1f} minutes)\")\n",
        "print(f\"   Session: {SESSION_NAME}\")\n",
        "print(f\"   Batching: Every 2 minutes (120 seconds)\")\n",
        "print(f\"   Output: data/sessions/{SESSION_NAME}/ + data/alltime/\")\n",
        "\n",
        "# Common duration options\n",
        "print(f\"\\nâ±ï¸ Common Duration Options:\")\n",
        "print(f\"   30 seconds (quick test): DURATION_SECONDS = 30\")\n",
        "print(f\"   10 minutes (short): DURATION_SECONDS = 600\") \n",
        "print(f\"   20 minutes (medium): DURATION_SECONDS = 1200\")\n",
        "print(f\"   30 minutes (long): DURATION_SECONDS = 1800\")\n",
        "print(f\"   60 minutes (extended): DURATION_SECONDS = 3600\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### â–¶ï¸ Execute Collection\n",
        "\n",
        "Run the cell below to start data collection with your parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Check current alltime data BEFORE collection\n",
        "print(\"ðŸ“Š Current Alltime Data BEFORE Collection:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "keywords = [\"food_insecurity\", \"housing\", \"homeless\", \"unemployment\", \"gender_inequality\"]\n",
        "before_counts = {}\n",
        "\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file):\n",
        "        with open(alltime_file, 'r') as f:\n",
        "            count = sum(1 for line in f)\n",
        "        before_counts[keyword] = count\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: {count} posts\")\n",
        "    else:\n",
        "        before_counts[keyword] = 0\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: 0 posts\")\n",
        "\n",
        "total_before = sum(before_counts.values())\n",
        "print(f\"\\nðŸ“ˆ Total Before: {total_before} posts\")\n",
        "\n",
        "print(f\"\\nðŸš€ Starting Collection...\")\n",
        "print(f\"   Duration: {DURATION_SECONDS} seconds ({DURATION_SECONDS/60:.1f} minutes)\")\n",
        "print(f\"   Session: {SESSION_NAME}\")\n",
        "print(f\"   Batching: Every 2 minutes\")\n",
        "\n",
        "# Run collection\n",
        "start_time = time.time()\n",
        "try:\n",
        "    result = subprocess.run([\n",
        "        'python', 'bluesky_social_justice_collector.py',\n",
        "        '--duration', str(DURATION_SECONDS),\n",
        "        '--session_name', SESSION_NAME\n",
        "    ], capture_output=True, text=True, timeout=DURATION_SECONDS + 60)\n",
        "    \n",
        "    print(\"âœ… Collection completed!\")\n",
        "    print(\"\\nðŸ“‹ Collection Output:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(result.stdout[-1000:])  # Show last 1000 characters\n",
        "    \n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"â° Collection timed out (normal for long runs)\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Collection error: {e}\")\n",
        "\n",
        "actual_duration = time.time() - start_time\n",
        "print(f\"\\nâ±ï¸ Actual runtime: {actual_duration/60:.1f} minutes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ“Š Collection Results & Output Directory\n",
        "\n",
        "Check the results and see what data was collected.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check AFTER collection results\n",
        "print(\"ðŸ“Š Collection Results:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check alltime data AFTER collection\n",
        "after_counts = {}\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file):\n",
        "        with open(alltime_file, 'r') as f:\n",
        "            count = sum(1 for line in f)\n",
        "        after_counts[keyword] = count\n",
        "        growth = count - before_counts.get(keyword, 0)\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: {count} posts (+{growth} new)\")\n",
        "    else:\n",
        "        after_counts[keyword] = 0\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: 0 posts\")\n",
        "\n",
        "total_after = sum(after_counts.values())\n",
        "total_growth = total_after - total_before\n",
        "\n",
        "print(f\"\\nðŸ“ˆ Total Growth: {total_before} â†’ {total_after} (+{total_growth} new posts)\")\n",
        "\n",
        "# Show output directories\n",
        "print(f\"\\nðŸ“ Output Directories:\")\n",
        "print(f\"   Session data: data/sessions/{SESSION_NAME}/\")\n",
        "print(f\"   Alltime data: data/alltime/\")\n",
        "\n",
        "# Check session directory\n",
        "session_dir = f\"data/sessions/{SESSION_NAME}\"\n",
        "if os.path.exists(session_dir):\n",
        "    session_files = [f for f in os.listdir(session_dir) if f.endswith('.jsonl')]\n",
        "    print(f\"\\nðŸ“‚ Session Files Created:\")\n",
        "    for file in session_files:\n",
        "        file_path = os.path.join(session_dir, file)\n",
        "        with open(file_path, 'r') as f:\n",
        "            count = sum(1 for line in f)\n",
        "        print(f\"   {file}: {count} posts\")\n",
        "\n",
        "# Show sample of latest collected data\n",
        "print(f\"\\nðŸ“ Sample of Latest Data:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file) and after_counts[keyword] > before_counts.get(keyword, 0):\n",
        "        try:\n",
        "            # Get last post\n",
        "            with open(alltime_file, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            if lines:\n",
        "                last_post = json.loads(lines[-1].strip())\n",
        "                print(f\"\\nðŸŽ¯ Latest {keyword.replace('_', ' ').title()} post:\")\n",
        "                print(f\"   Author: @{last_post.get('author_handle', 'unknown')}\")\n",
        "                print(f\"   Followers: {last_post.get('author_followers_count', 0):,}\")\n",
        "                print(f\"   Text: {last_post.get('text', '')[:100]}...\")\n",
        "                print(f\"   Session: {last_post.get('session_name', 'unknown')}\")\n",
        "                break\n",
        "        except:\n",
        "            continue\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
