{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ¦‹ Bluesky Social Justice Data Collection & Analysis - HYBRID VERSION\n",
        "## DFP F25 Social Media Blue Team\n",
        "\n",
        "This notebook provides a comprehensive interface for collecting and analyzing social justice data from Bluesky using **DUAL collection methods**.\n",
        "\n",
        "## ðŸš€ **NEW: HYBRID COLLECTION SYSTEM**\n",
        "\n",
        "### **Collection Methods Available:**\n",
        "\n",
        "1. **ðŸ”¥ Firehose Collection (Real-time)**\n",
        "   - Live stream of current posts as they happen\n",
        "   - Best for monitoring ongoing conversations\n",
        "   - Duration-based collection\n",
        "\n",
        "2. **ðŸ” Search API Collection (Historical) - NEW!**\n",
        "   - Native search with deep pagination (Option A implementation)\n",
        "   - Systematic historical data collection\n",
        "   - Date range filtering and cursor-based navigation\n",
        "   - Enhanced query design with exact phrases and hashtags\n",
        "\n",
        "3. **âš¡ Hybrid Collection (Both) - NEW!**\n",
        "   - Historical data first (search API)\n",
        "   - Then real-time monitoring (firehose)\n",
        "   - Complete coverage of past and present\n",
        "\n",
        "### **Key Features:**\n",
        "- âœ… **Dual collection methods** (firehose + search API)\n",
        "- âœ… **Deep pagination** with cursor persistence\n",
        "- âœ… **Date range filtering** for historical collection\n",
        "- âœ… **Author influence metrics** (follower counts, verification)\n",
        "- âœ… **Enhanced search queries** (exact phrases, hashtags)\n",
        "- âœ… **Session-based organization** with alltime datasets\n",
        "- âœ… **Rich content analysis** (hashtags, media, emotions)\n",
        "- âœ… **Secure authentication** from external credentials file\n",
        "\n",
        "### **Social Justice Keywords:**\n",
        "- Food insecurity\n",
        "- Housing crisis  \n",
        "- Homelessness\n",
        "- Unemployment\n",
        "- Gender inequality\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ Setup and Dependencies\n",
        "\n",
        "First, let's import all required libraries and check our setup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… atproto library available\n",
            "ðŸ”§ Setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timezone\n",
        "from collections import defaultdict, Counter\n",
        "import re\n",
        "\n",
        "# Check if atproto is available\n",
        "try:\n",
        "    from atproto import Client\n",
        "    print(\"âœ… atproto library available\")\n",
        "except ImportError:\n",
        "    print(\"âŒ atproto not found. Install with: pip install atproto\")\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"ðŸ”§ Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Load and Explore Collected Data\n",
        "\n",
        "Let's examine the social justice data we've collected from Bluesky.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Loading Alltime Data:\n",
            "========================================\n",
            "âœ… Food Insecurity: 66 posts\n",
            "âœ… Housing: 36 posts\n",
            "âœ… Homeless: 83 posts\n",
            "âœ… Unemployment: 120 posts\n",
            "âœ… Gender Inequality: 34 posts\n",
            "\n",
            "ðŸ“ˆ Total Posts Loaded: 339\n",
            "âœ… DataFrame created with 339 rows and 44 columns\n",
            "\n",
            "ðŸ” Data Structure:\n",
            "   Post fields: uri, text, created_at, author_handle\n",
            "   Author fields: followers_count, influence_score, verified\n",
            "   Content fields: word_count, hashtags, emotion_score\n",
            "   Session fields: session_name, collected_at\n"
          ]
        }
      ],
      "source": [
        "# Load all alltime data for analysis\n",
        "keywords = [\"food_insecurity\", \"housing\", \"homeless\", \"unemployment\", \"gender_inequality\"]\n",
        "all_data = []\n",
        "keyword_counts = {}\n",
        "\n",
        "print(\"ðŸ“Š Loading Alltime Data:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file):\n",
        "        keyword_posts = []\n",
        "        with open(alltime_file, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    post = json.loads(line.strip())\n",
        "                    all_data.append(post)\n",
        "                    keyword_posts.append(post)\n",
        "                except json.JSONDecodeError:\n",
        "                    continue\n",
        "        \n",
        "        keyword_counts[keyword] = len(keyword_posts)\n",
        "        print(f\"âœ… {keyword.replace('_', ' ').title()}: {len(keyword_posts):,} posts\")\n",
        "    else:\n",
        "        keyword_counts[keyword] = 0\n",
        "        print(f\"âŒ {keyword.replace('_', ' ').title()}: No data\")\n",
        "\n",
        "print(f\"\\nðŸ“ˆ Total Posts Loaded: {len(all_data):,}\")\n",
        "\n",
        "# Convert to DataFrame for analysis\n",
        "if all_data:\n",
        "    df = pd.DataFrame(all_data)\n",
        "    print(f\"âœ… DataFrame created with {len(df)} rows and {len(df.columns)} columns\")\n",
        "    \n",
        "    # Show data structure\n",
        "    print(f\"\\nðŸ” Data Structure:\")\n",
        "    print(f\"   Post fields: uri, text, created_at, author_handle\")\n",
        "    print(f\"   Author fields: followers_count, influence_score, verified\")\n",
        "    print(f\"   Content fields: word_count, hashtags, emotion_score\")\n",
        "    print(f\"   Session fields: session_name, collected_at\")\n",
        "else:\n",
        "    df = pd.DataFrame()\n",
        "    print(\"âŒ No data available - run collection first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ“‹ Collection Method Details\n",
        "\n",
        "**ðŸ”¥ Firehose Collection** (Original Method)\n",
        "- **How it works**: Connects to live Bluesky firehose stream\n",
        "- **Data type**: Real-time posts as they happen\n",
        "- **Best for**: Monitoring current conversations, trending topics\n",
        "- **Parameters**: Duration in seconds/minutes\n",
        "- **Coverage**: Only new posts during collection window\n",
        "\n",
        "**ðŸ” Search API Collection** (NEW - Option A Implementation)  \n",
        "- **How it works**: Uses `GET /xrpc/app.bsky.feed.searchPosts` with cursor pagination\n",
        "- **Data type**: Historical posts with deep pagination\n",
        "- **Best for**: Systematic research, historical analysis, comprehensive datasets\n",
        "- **Parameters**: Date ranges, maximum posts per keyword\n",
        "- **Coverage**: Can collect posts from weeks/months back\n",
        "- **Features**: \n",
        "  - Enhanced search queries (exact phrases, hashtags)\n",
        "  - Date range filtering (`record.createdAt` checking)\n",
        "  - Cursor-based pagination (no missed posts)\n",
        "  - Rate limiting and error handling\n",
        "\n",
        "**âš¡ Hybrid Collection** (RECOMMENDED)\n",
        "- **How it works**: Search API first for historical data, then firehose for real-time\n",
        "- **Data type**: Complete coverage of both historical and current data\n",
        "- **Best for**: Comprehensive research projects\n",
        "- **Parameters**: Both date ranges and duration\n",
        "- **Coverage**: Historical baseline + ongoing monitoring\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ” Enhanced Search Queries (Option A)\n",
        "\n",
        "The new search API uses optimized queries designed to reduce noise and maximize relevant results:\n",
        "\n",
        "**Food Insecurity:**\n",
        "- `\"food insecurity\"`, `\"food insecure\"`, `#foodinsecurity`\n",
        "- `\"hunger crisis\"`, `\"food desert\"`, `\"SNAP benefits\"`\n",
        "- `\"food bank\"`, `\"food pantry\"`, `\"EBT\"`, `\"WIC\"`\n",
        "\n",
        "**Housing:**\n",
        "- `\"housing crisis\"`, `\"affordable housing\"`, `#housingcrisis`\n",
        "- `\"rent crisis\"`, `\"housing shortage\"`, `\"eviction\"`\n",
        "- `\"housing costs\"`, `\"rent burden\"`, `\"gentrification\"`\n",
        "\n",
        "**Homelessness:**\n",
        "- `\"homeless\"`, `\"homelessness\"`, `#homeless`\n",
        "- `\"unhoused\"`, `\"rough sleeping\"`, `\"encampment\"`\n",
        "- `\"shelter\"`, `\"street sleeping\"`, `\"housing first\"`\n",
        "\n",
        "**Unemployment:**\n",
        "- `\"unemployment\"`, `\"unemployed\"`, `#unemployment`\n",
        "- `\"job loss\"`, `\"layoffs\"`, `\"jobless\"`\n",
        "- `\"unemployment benefits\"`, `\"fired\"`, `\"laid off\"`\n",
        "\n",
        "**Gender Inequality:**\n",
        "- `\"gender inequality\"`, `\"gender gap\"`, `#gendergap`\n",
        "- `\"pay gap\"`, `\"wage gap\"`, `\"gender discrimination\"`\n",
        "- `\"equal pay\"`, `\"workplace inequality\"`, `\"glass ceiling\"`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Data Collection Execution - HYBRID VERSION\n",
        "\n",
        "### Collection Method Selection\n",
        "\n",
        "Choose your collection approach and set parameters below. The hybrid collector now supports three methods:\n",
        "\n",
        "1. **ðŸ”¥ Firehose**: Real-time stream collection\n",
        "2. **ðŸ” Search API**: Historical data with pagination  \n",
        "3. **âš¡ Both**: Historical first, then real-time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š HYBRID Collection Configuration:\n",
            "   Method: both\n",
            "   Session: hybrid_test\n",
            "   ðŸ”¥ Firehose Duration: 300 seconds (5.0 minutes)\n",
            "   ðŸ” Search Days Back: 7 days\n",
            "   ðŸ” Max Posts/Keyword: 100\n",
            "   ðŸ“ Output: data/sessions/hybrid_test/ + data/alltime/\n"
          ]
        }
      ],
      "source": [
        "# ðŸ”§ COLLECTION PARAMETERS - HYBRID VERSION - Edit these values\n",
        "\n",
        "# ===== COLLECTION METHOD =====\n",
        "# Choose: 'firehose', 'search', or 'both'\n",
        "COLLECTION_METHOD = \"both\"  # ðŸ”¥ firehose | ðŸ” search | âš¡ both\n",
        "\n",
        "# ===== FIREHOSE PARAMETERS (for real-time collection) =====\n",
        "DURATION_SECONDS = 300  # 5 minutes (for firehose method)\n",
        "\n",
        "# ===== SEARCH API PARAMETERS (for historical collection) =====\n",
        "DAYS_BACK = 7  # Days back from now (alternative to specific dates)\n",
        "# START_DATE = \"2024-09-01\"  # Optional: specific start date (YYYY-MM-DD)\n",
        "# END_DATE = \"2024-09-18\"    # Optional: specific end date (YYYY-MM-DD)\n",
        "MAX_POSTS_PER_KEYWORD = 100  # Maximum posts per keyword for search\n",
        "\n",
        "# ===== GENERAL PARAMETERS =====\n",
        "SESSION_NAME = \"hybrid_test\"  # Custom session name (optional)\n",
        "\n",
        "# Display configuration\n",
        "print(f\"ðŸ“Š HYBRID Collection Configuration:\")\n",
        "print(f\"   Method: {COLLECTION_METHOD}\")\n",
        "print(f\"   Session: {SESSION_NAME}\")\n",
        "\n",
        "if COLLECTION_METHOD in ['firehose', 'both']:\n",
        "    duration_minutes = DURATION_SECONDS / 60\n",
        "    print(f\"   ðŸ”¥ Firehose Duration: {DURATION_SECONDS} seconds ({duration_minutes:.1f} minutes)\")\n",
        "\n",
        "if COLLECTION_METHOD in ['search', 'both']:\n",
        "    print(f\"   ðŸ” Search Days Back: {DAYS_BACK} days\")\n",
        "    print(f\"   ðŸ” Max Posts/Keyword: {MAX_POSTS_PER_KEYWORD}\")\n",
        "\n",
        "print(f\"   ðŸ“ Output: data/sessions/{SESSION_NAME}/ + data/alltime/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### â–¶ï¸ Execute HYBRID Collection\n",
        "\n",
        "Run the cell below to start data collection with your chosen method and parameters.\n",
        "\n",
        "**What happens:**\n",
        "- **ðŸ” Search method**: Collects historical data using native search API with pagination\n",
        "- **ðŸ”¥ Firehose method**: Collects real-time data from live stream  \n",
        "- **âš¡ Both method**: Historical data first, then real-time (recommended for comprehensive coverage)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Current Alltime Data BEFORE Collection:\n",
            "==================================================\n",
            "   Food Insecurity: 66 posts\n",
            "   Housing: 36 posts\n",
            "   Homeless: 83 posts\n",
            "   Unemployment: 120 posts\n",
            "   Gender Inequality: 34 posts\n",
            "\n",
            "ðŸ“ˆ Total Before: 339 posts\n",
            "\n",
            "ðŸš€ Starting HYBRID Collection...\n",
            "   Method: both\n",
            "   Session: hybrid_test\n",
            "   ðŸ”¥ Firehose Duration: 300 seconds (5.0 minutes)\n",
            "   ðŸ” Search Days Back: 7 days\n",
            "   ðŸ” Max Posts/Keyword: 100\n",
            "   ðŸ”§ Command: python bluesky_social_justice_collector.py --method both --session_name hybrid_test --duration 300 --days-back 7 --max-posts 100\n",
            "â° Collection timed out (normal for long runs)\n",
            "\n",
            "â±ï¸ Actual runtime: 7.0 minutes\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Check current alltime data BEFORE collection\n",
        "print(\"ðŸ“Š Current Alltime Data BEFORE Collection:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "keywords = [\"food_insecurity\", \"housing\", \"homeless\", \"unemployment\", \"gender_inequality\"]\n",
        "before_counts = {}\n",
        "\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file):\n",
        "        with open(alltime_file, 'r') as f:\n",
        "            count = sum(1 for line in f)\n",
        "        before_counts[keyword] = count\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: {count} posts\")\n",
        "    else:\n",
        "        before_counts[keyword] = 0\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: 0 posts\")\n",
        "\n",
        "total_before = sum(before_counts.values())\n",
        "print(f\"\\nðŸ“ˆ Total Before: {total_before} posts\")\n",
        "\n",
        "print(f\"\\nðŸš€ Starting HYBRID Collection...\")\n",
        "print(f\"   Method: {COLLECTION_METHOD}\")\n",
        "print(f\"   Session: {SESSION_NAME}\")\n",
        "\n",
        "if COLLECTION_METHOD in ['firehose', 'both']:\n",
        "    print(f\"   ðŸ”¥ Firehose Duration: {DURATION_SECONDS} seconds ({DURATION_SECONDS/60:.1f} minutes)\")\n",
        "if COLLECTION_METHOD in ['search', 'both']:\n",
        "    print(f\"   ðŸ” Search Days Back: {DAYS_BACK} days\")\n",
        "    print(f\"   ðŸ” Max Posts/Keyword: {MAX_POSTS_PER_KEYWORD}\")\n",
        "\n",
        "# Build command arguments\n",
        "cmd_args = [\n",
        "    'python', 'bluesky_social_justice_collector.py',\n",
        "    '--method', COLLECTION_METHOD,\n",
        "    '--session_name', SESSION_NAME\n",
        "]\n",
        "\n",
        "# Add method-specific arguments\n",
        "if COLLECTION_METHOD in ['firehose', 'both'] and DURATION_SECONDS:\n",
        "    cmd_args.extend(['--duration', str(DURATION_SECONDS)])\n",
        "\n",
        "if COLLECTION_METHOD in ['search', 'both']:\n",
        "    if DAYS_BACK:\n",
        "        cmd_args.extend(['--days-back', str(DAYS_BACK)])\n",
        "    cmd_args.extend(['--max-posts', str(MAX_POSTS_PER_KEYWORD)])\n",
        "\n",
        "print(f\"   ðŸ”§ Command: {' '.join(cmd_args)}\")\n",
        "\n",
        "# Run collection\n",
        "start_time = time.time()\n",
        "try:\n",
        "    # Set timeout based on method\n",
        "    timeout_seconds = 120  # Default for search\n",
        "    if COLLECTION_METHOD in ['firehose', 'both'] and DURATION_SECONDS:\n",
        "        timeout_seconds = DURATION_SECONDS + 120\n",
        "    \n",
        "    result = subprocess.run(cmd_args, capture_output=True, text=True, timeout=timeout_seconds)\n",
        "    \n",
        "    print(\"âœ… Collection completed!\")\n",
        "    print(\"\\nðŸ“‹ Collection Output:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(result.stdout[-1500:])  # Show last 1500 characters\n",
        "    \n",
        "    if result.stderr:\n",
        "        print(\"\\nâš ï¸ Warnings/Errors:\")\n",
        "        print(result.stderr[-500:])\n",
        "    \n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"â° Collection timed out (normal for long runs)\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Collection error: {e}\")\n",
        "\n",
        "actual_duration = time.time() - start_time\n",
        "print(f\"\\nâ±ï¸ Actual runtime: {actual_duration/60:.1f} minutes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ“Š Collection Results & Output Directory\n",
        "\n",
        "Check the results and see what data was collected.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Collection Results:\n",
            "==================================================\n",
            "   Food Insecurity: 66 posts (+0 new)\n",
            "   Housing: 36 posts (+0 new)\n",
            "   Homeless: 83 posts (+0 new)\n",
            "   Unemployment: 120 posts (+0 new)\n",
            "   Gender Inequality: 34 posts (+0 new)\n",
            "\n",
            "ðŸ“ˆ Total Growth: 339 â†’ 339 (+0 new posts)\n",
            "\n",
            "ðŸ“ Output Directories:\n",
            "   Session data: data/sessions/hybrid_test/\n",
            "   Alltime data: data/alltime/\n",
            "\n",
            "ðŸ“‚ Session Files Created:\n",
            "   homeless_posts.jsonl: 683 posts\n",
            "   food_insecurity_posts.jsonl: 486 posts\n",
            "   housing_posts.jsonl: 491 posts\n",
            "   unemployment_posts.jsonl: 200 posts\n",
            "\n",
            "ðŸ“ Sample of Latest Data:\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Check AFTER collection results\n",
        "print(\"ðŸ“Š Collection Results:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check alltime data AFTER collection\n",
        "after_counts = {}\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file):\n",
        "        with open(alltime_file, 'r') as f:\n",
        "            count = sum(1 for line in f)\n",
        "        after_counts[keyword] = count\n",
        "        growth = count - before_counts.get(keyword, 0)\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: {count} posts (+{growth} new)\")\n",
        "    else:\n",
        "        after_counts[keyword] = 0\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: 0 posts\")\n",
        "\n",
        "total_after = sum(after_counts.values())\n",
        "total_growth = total_after - total_before\n",
        "\n",
        "print(f\"\\nðŸ“ˆ Total Growth: {total_before} â†’ {total_after} (+{total_growth} new posts)\")\n",
        "\n",
        "# Show output directories\n",
        "print(f\"\\nðŸ“ Output Directories:\")\n",
        "print(f\"   Session data: data/sessions/{SESSION_NAME}/\")\n",
        "print(f\"   Alltime data: data/alltime/\")\n",
        "\n",
        "# Check session directory\n",
        "session_dir = f\"data/sessions/{SESSION_NAME}\"\n",
        "if os.path.exists(session_dir):\n",
        "    session_files = [f for f in os.listdir(session_dir) if f.endswith('.jsonl')]\n",
        "    print(f\"\\nðŸ“‚ Session Files Created:\")\n",
        "    for file in session_files:\n",
        "        file_path = os.path.join(session_dir, file)\n",
        "        with open(file_path, 'r') as f:\n",
        "            count = sum(1 for line in f)\n",
        "        print(f\"   {file}: {count} posts\")\n",
        "\n",
        "# Show sample of latest collected data\n",
        "print(f\"\\nðŸ“ Sample of Latest Data:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file) and after_counts[keyword] > before_counts.get(keyword, 0):\n",
        "        try:\n",
        "            # Get last post\n",
        "            with open(alltime_file, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            if lines:\n",
        "                last_post = json.loads(lines[-1].strip())\n",
        "                print(f\"\\nðŸŽ¯ Latest {keyword.replace('_', ' ').title()} post:\")\n",
        "                print(f\"   Author: @{last_post.get('author_handle', 'unknown')}\")\n",
        "                print(f\"   Followers: {last_post.get('author_followers_count', 0):,}\")\n",
        "                print(f\"   Text: {last_post.get('text', '')[:100]}...\")\n",
        "                print(f\"   Session: {last_post.get('session_name', 'unknown')}\")\n",
        "                break\n",
        "        except:\n",
        "            continue\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
