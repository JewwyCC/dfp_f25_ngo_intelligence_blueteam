{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü¶ã Bluesky Social Justice Data Collection & Analysis\n",
        "## DFP F25 Social Media Blue Team\n",
        "\n",
        "This notebook provides an interactive interface for collecting and analyzing social justice data from Bluesky with rich author influence metrics.\n",
        "\n",
        "**Key Features:**\n",
        "- ‚úÖ **Real-time data collection** with Bluesky firehose\n",
        "- ‚úÖ **Author influence metrics** (follower counts, verification status)\n",
        "- ‚úÖ **Session-based organization** with alltime datasets\n",
        "- ‚úÖ **2-minute batching** with automatic alltime updates\n",
        "- ‚úÖ **Rich content analysis** (hashtags, media, emotions)\n",
        "- ‚úÖ **Secure authentication** from external credentials file\n",
        "\n",
        "**Social Justice Keywords:**\n",
        "- Food insecurity\n",
        "- Housing crisis\n",
        "- Homelessness\n",
        "- Unemployment\n",
        "- Gender inequality\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Setup and Dependencies\n",
        "\n",
        "First, let's import all required libraries and check our setup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timezone\n",
        "from collections import defaultdict, Counter\n",
        "import re\n",
        "\n",
        "# Check if atproto is available\n",
        "try:\n",
        "    from atproto import Client\n",
        "    print(\"‚úÖ atproto library available\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå atproto not found. Install with: pip install atproto\")\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üîß Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Load and Explore Collected Data\n",
        "\n",
        "Let's examine the social justice data we've collected from Bluesky.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load all alltime data for analysis\n",
        "keywords = [\"food_insecurity\", \"housing\", \"homeless\", \"unemployment\", \"gender_inequality\"]\n",
        "all_data = []\n",
        "keyword_counts = {}\n",
        "\n",
        "print(\"üìä Loading Alltime Data:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file):\n",
        "        keyword_posts = []\n",
        "        with open(alltime_file, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    post = json.loads(line.strip())\n",
        "                    all_data.append(post)\n",
        "                    keyword_posts.append(post)\n",
        "                except json.JSONDecodeError:\n",
        "                    continue\n",
        "        \n",
        "        keyword_counts[keyword] = len(keyword_posts)\n",
        "        print(f\"‚úÖ {keyword.replace('_', ' ').title()}: {len(keyword_posts):,} posts\")\n",
        "    else:\n",
        "        keyword_counts[keyword] = 0\n",
        "        print(f\"‚ùå {keyword.replace('_', ' ').title()}: No data\")\n",
        "\n",
        "print(f\"\\nüìà Total Posts Loaded: {len(all_data):,}\")\n",
        "\n",
        "# Convert to DataFrame for analysis\n",
        "if all_data:\n",
        "    df = pd.DataFrame(all_data)\n",
        "    print(f\"‚úÖ DataFrame created with {len(df)} rows and {len(df.columns)} columns\")\n",
        "    \n",
        "    # Show data structure\n",
        "    print(f\"\\nüîç Data Structure:\")\n",
        "    print(f\"   Post fields: uri, text, created_at, author_handle\")\n",
        "    print(f\"   Author fields: followers_count, influence_score, verified\")\n",
        "    print(f\"   Content fields: word_count, hashtags, emotion_score\")\n",
        "    print(f\"   Session fields: session_name, collected_at\")\n",
        "else:\n",
        "    df = pd.DataFrame()\n",
        "    print(\"‚ùå No data available - run collection first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Data Collection Execution\n",
        "\n",
        "### Collection Parameters\n",
        "\n",
        "Set your collection duration below, then run the execution cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß COLLECTION PARAMETERS - Edit these values\n",
        "DURATION_SECONDS = 300  # 5 minutes (change to 30, 600, 1200, 1800, 3600 as needed)\n",
        "SESSION_NAME = \"notebook_test\"  # Custom session name (optional)\n",
        "\n",
        "# Duration conversion helper\n",
        "duration_minutes = DURATION_SECONDS / 60\n",
        "print(f\"üìä Collection Parameters:\")\n",
        "print(f\"   Duration: {DURATION_SECONDS} seconds ({duration_minutes:.1f} minutes)\")\n",
        "print(f\"   Session: {SESSION_NAME}\")\n",
        "print(f\"   Batching: Every 2 minutes (120 seconds)\")\n",
        "print(f\"   Output: data/sessions/{SESSION_NAME}/ + data/alltime/\")\n",
        "\n",
        "# Common duration options\n",
        "print(f\"\\n‚è±Ô∏è Common Duration Options:\")\n",
        "print(f\"   30 seconds (quick test): DURATION_SECONDS = 30\")\n",
        "print(f\"   10 minutes (short): DURATION_SECONDS = 600\") \n",
        "print(f\"   20 minutes (medium): DURATION_SECONDS = 1200\")\n",
        "print(f\"   30 minutes (long): DURATION_SECONDS = 1800\")\n",
        "print(f\"   60 minutes (extended): DURATION_SECONDS = 3600\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚ñ∂Ô∏è Execute Collection\n",
        "\n",
        "Run the cell below to start data collection with your parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Check current alltime data BEFORE collection\n",
        "print(\"üìä Current Alltime Data BEFORE Collection:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "keywords = [\"food_insecurity\", \"housing\", \"homeless\", \"unemployment\", \"gender_inequality\"]\n",
        "before_counts = {}\n",
        "\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file):\n",
        "        with open(alltime_file, 'r') as f:\n",
        "            count = sum(1 for line in f)\n",
        "        before_counts[keyword] = count\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: {count} posts\")\n",
        "    else:\n",
        "        before_counts[keyword] = 0\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: 0 posts\")\n",
        "\n",
        "total_before = sum(before_counts.values())\n",
        "print(f\"\\nüìà Total Before: {total_before} posts\")\n",
        "\n",
        "print(f\"\\nüöÄ Starting Collection...\")\n",
        "print(f\"   Duration: {DURATION_SECONDS} seconds ({DURATION_SECONDS/60:.1f} minutes)\")\n",
        "print(f\"   Session: {SESSION_NAME}\")\n",
        "print(f\"   Batching: Every 2 minutes\")\n",
        "\n",
        "# Run collection\n",
        "start_time = time.time()\n",
        "try:\n",
        "    result = subprocess.run([\n",
        "        'python', 'bluesky_social_justice_collector.py',\n",
        "        '--duration', str(DURATION_SECONDS),\n",
        "        '--session_name', SESSION_NAME\n",
        "    ], capture_output=True, text=True, timeout=DURATION_SECONDS + 60)\n",
        "    \n",
        "    print(\"‚úÖ Collection completed!\")\n",
        "    print(\"\\nüìã Collection Output:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(result.stdout[-1000:])  # Show last 1000 characters\n",
        "    \n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"‚è∞ Collection timed out (normal for long runs)\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Collection error: {e}\")\n",
        "\n",
        "actual_duration = time.time() - start_time\n",
        "print(f\"\\n‚è±Ô∏è Actual runtime: {actual_duration/60:.1f} minutes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Collection Results & Output Directory\n",
        "\n",
        "Check the results and see what data was collected.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check AFTER collection results\n",
        "print(\"üìä Collection Results:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check alltime data AFTER collection\n",
        "after_counts = {}\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file):\n",
        "        with open(alltime_file, 'r') as f:\n",
        "            count = sum(1 for line in f)\n",
        "        after_counts[keyword] = count\n",
        "        growth = count - before_counts.get(keyword, 0)\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: {count} posts (+{growth} new)\")\n",
        "    else:\n",
        "        after_counts[keyword] = 0\n",
        "        print(f\"   {keyword.replace('_', ' ').title()}: 0 posts\")\n",
        "\n",
        "total_after = sum(after_counts.values())\n",
        "total_growth = total_after - total_before\n",
        "\n",
        "print(f\"\\nüìà Total Growth: {total_before} ‚Üí {total_after} (+{total_growth} new posts)\")\n",
        "\n",
        "# Show output directories\n",
        "print(f\"\\nüìÅ Output Directories:\")\n",
        "print(f\"   Session data: data/sessions/{SESSION_NAME}/\")\n",
        "print(f\"   Alltime data: data/alltime/\")\n",
        "\n",
        "# Check session directory\n",
        "session_dir = f\"data/sessions/{SESSION_NAME}\"\n",
        "if os.path.exists(session_dir):\n",
        "    session_files = [f for f in os.listdir(session_dir) if f.endswith('.jsonl')]\n",
        "    print(f\"\\nüìÇ Session Files Created:\")\n",
        "    for file in session_files:\n",
        "        file_path = os.path.join(session_dir, file)\n",
        "        with open(file_path, 'r') as f:\n",
        "            count = sum(1 for line in f)\n",
        "        print(f\"   {file}: {count} posts\")\n",
        "\n",
        "# Show sample of latest collected data\n",
        "print(f\"\\nüìù Sample of Latest Data:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "for keyword in keywords:\n",
        "    alltime_file = f\"data/alltime/{keyword}_alltime.jsonl\"\n",
        "    if os.path.exists(alltime_file) and after_counts[keyword] > before_counts.get(keyword, 0):\n",
        "        try:\n",
        "            # Get last post\n",
        "            with open(alltime_file, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            if lines:\n",
        "                last_post = json.loads(lines[-1].strip())\n",
        "                print(f\"\\nüéØ Latest {keyword.replace('_', ' ').title()} post:\")\n",
        "                print(f\"   Author: @{last_post.get('author_handle', 'unknown')}\")\n",
        "                print(f\"   Followers: {last_post.get('author_followers_count', 0):,}\")\n",
        "                print(f\"   Text: {last_post.get('text', '')[:100]}...\")\n",
        "                print(f\"   Session: {last_post.get('session_name', 'unknown')}\")\n",
        "                break\n",
        "        except:\n",
        "            continue\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
